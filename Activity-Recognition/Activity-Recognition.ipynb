{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FYP.ipynb","provenance":[],"mount_file_id":"1y0SZFb3mKw9brjndXUWXGZL37mf8QCEn","authorship_tag":"ABX9TyPVc8/5ih06DmOe3gSO9yEs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"ApGQPT8LmorC","executionInfo":{"status":"ok","timestamp":1628072709283,"user_tz":-330,"elapsed":775,"user":{"displayName":"PRAJWAL RAJ B R","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuRCrK1ZO7-fWr_9umDkGnubnaSb19F5itGz5O=s64","userId":"02884760098419565384"}}},"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPool2D\n","from tensorflow.keras.metrics import categorical_crossentropy\n","import numpy as np\n","from tensorflow.keras.models import Model\n","import os\n","import matplotlib.pyplot as plt"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"Em_RaOkSmuFO","executionInfo":{"status":"ok","timestamp":1628070454927,"user_tz":-330,"elapsed":12389,"user":{"displayName":"PRAJWAL RAJ B R","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuRCrK1ZO7-fWr_9umDkGnubnaSb19F5itGz5O=s64","userId":"02884760098419565384"}}},"source":["model = tf.keras.models.load_model('/content/drive/MyDrive/NewActivity/30_05_2021_VGG19.h5')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"lDAbdXSznCVe","executionInfo":{"status":"ok","timestamp":1628070454930,"user_tz":-330,"elapsed":23,"user":{"displayName":"PRAJWAL RAJ B R","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuRCrK1ZO7-fWr_9umDkGnubnaSb19F5itGz5O=s64","userId":"02884760098419565384"}}},"source":["class_indices = {\n"," 'bear': 0,\n"," 'bull': 12,\n"," 'crocodile': 14,\n"," 'deer': 13,\n"," 'elephant': 1,\n"," 'fox': 8,\n"," 'giraffe': 11,\n"," 'horse': 5,\n"," 'kangaroo': 9,\n"," 'leopard': 2,\n"," 'lion': 3,\n"," 'rhino': 10,\n"," 'tiger': 7,\n"," 'wolf': 4,\n"," 'zebra': 6\n","}"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"BiSJSmz6nH-P","executionInfo":{"status":"ok","timestamp":1628070454933,"user_tz":-330,"elapsed":21,"user":{"displayName":"PRAJWAL RAJ B R","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuRCrK1ZO7-fWr_9umDkGnubnaSb19F5itGz5O=s64","userId":"02884760098419565384"}}},"source":["from tensorflow.keras.applications.vgg19 import preprocess_input\n","def predict_class(img_array):\n","    img_batch = np.expand_dims(img_array, axis=0)\n","    img_preprocessed = preprocess_input(img_batch)\n","    prediction = model.predict(img_preprocessed)\n","    return next((k for k, v in class_indices.items() if v == prediction.argmax()))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"2n6vEHj_nQTF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628070667503,"user_tz":-330,"elapsed":212586,"user":{"displayName":"PRAJWAL RAJ B R","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuRCrK1ZO7-fWr_9umDkGnubnaSb19F5itGz5O=s64","userId":"02884760098419565384"}},"outputId":"2757171b-b052-4d9b-b16e-77a7fb1cda50"},"source":["import numpy as np\n","import cv2\n","import os\n","import sys\n","import math\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score\n","from skimage.feature import hog\n","\n","labels = {}\n","\n","def dataset(files, mode):\n","    \n","    X = []\n","    y = []\n","\n","    indx = 0\n","\n","    for filename in files:\n","\n","        img = cv2.imread(filename)\n","        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","        img = cv2.resize(img,(128,128))\n","\n","        des, hog_image = hog(img, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(4, 4), block_norm= 'L2',visualize=True)\n","\n","        if mode == 1:\n","            path = '/content/drive/MyDrive/NewActivity/Lion/data/train/'\n","        elif mode == 2:\n","            path = '/content/drive/MyDrive/NewActivity/Lion/data/test/'\n","        \n","        onlyFnm = filename.replace(path, '')\n","        index = onlyFnm.index('_')\n","        label = onlyFnm[index:-5]\n","                \n","        if mode == 1:\n","            if label not in labels.keys():\n","                labels[label] = indx\n","                indx += 1\n","\n","        X.append(des)\n","        y.append(labels[label])\n","\n","    return X, y\n","\n","files_train = [('/content/drive/MyDrive/NewActivity/Lion/data/train/' + f) for f in os.listdir(os.path.join('/content/drive/MyDrive/NewActivity/Lion/data','train'))]\n","files_test = [('/content/drive/MyDrive/NewActivity/Lion/data/test/' + f) for f in os.listdir(os.path.join('/content/drive/MyDrive/NewActivity/Lion/data','test'))]\n","\n","Xtrain, ytrain = dataset(files_train, 1)\n","Xtest, ytest = dataset(files_test, 2)\n","\n","Xtrain = np.array(Xtrain)\n","ytrain = np.array(ytrain)\n","Xtest = np.array(Xtest)\n","ytest = np.array(ytest)\n","\n","clfl = svm.SVC(kernel = 'linear')\n","# clf = svm.SVC(kernel = 'poly')\n","\n","clfl.fit(Xtrain, ytrain)\n","\n","ypred = clfl.predict(Xtest)\n","print(ypred,ytest)\n","\n","accuracy = accuracy_score(ytest, ypred) * 100\n","print(\"\\nAccuracy: %.2f\" % accuracy + \"%\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[1 1 1 0 0 0 0] [0 1 1 0 0 0 1]\n","\n","Accuracy: 71.43%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NU3USSzsxn0j","executionInfo":{"status":"ok","timestamp":1628070741436,"user_tz":-330,"elapsed":73942,"user":{"displayName":"PRAJWAL RAJ B R","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuRCrK1ZO7-fWr_9umDkGnubnaSb19F5itGz5O=s64","userId":"02884760098419565384"}},"outputId":"2d01bab8-b97c-442b-e60d-fabce143783b"},"source":["import numpy as np\n","import cv2\n","import os\n","import sys\n","import math\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score\n","from skimage.feature import hog\n","\n","labels = {}\n","\n","def dataset(files, mode):\n","    \n","    X = []\n","    y = []\n","\n","    indx = 0\n","\n","    for filename in files:\n","\n","        img = cv2.imread(filename)\n","        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","        img = cv2.resize(img,(128,128))\n","\n","        des, hog_image = hog(img, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(4, 4), block_norm= 'L2',visualize=True)\n","\n","        if mode == 1:\n","            path = '/content/drive/MyDrive/NewActivity/Tiger/data/train/'\n","        elif mode == 2:\n","            path = '/content/drive/MyDrive/NewActivity/Tiger/data/test/'\n","        \n","        onlyFnm = filename.replace(path, '')\n","        index = onlyFnm.index('_')\n","        label = onlyFnm[index:-5]\n","                \n","        if mode == 1:\n","            if label not in labels.keys():\n","                labels[label] = indx\n","                indx += 1\n","\n","        X.append(des)\n","        y.append(labels[label])\n","\n","    return X, y\n","\n","files_train = [('/content/drive/MyDrive/NewActivity/Tiger/data/train/' + f) for f in os.listdir(os.path.join('/content/drive/MyDrive/NewActivity/Tiger/data','train'))]\n","files_test = [('/content/drive/MyDrive/NewActivity/Tiger/data/test/' + f) for f in os.listdir(os.path.join('/content/drive/MyDrive/NewActivity/Tiger/data','test'))]\n","\n","Xtrain, ytrain = dataset(files_train, 1)\n","Xtest, ytest = dataset(files_test, 2)\n","\n","Xtrain = np.array(Xtrain)\n","ytrain = np.array(ytrain)\n","Xtest = np.array(Xtest)\n","ytest = np.array(ytest)\n","\n","clft = svm.SVC(kernel = 'linear')\n","# clf = svm.SVC(kernel = 'poly')\n","\n","clft.fit(Xtrain, ytrain)\n","\n","ypred = clft.predict(Xtest)\n","print(ypred,ytest)\n","\n","accuracy = accuracy_score(ytest, ypred) * 100\n","print(\"\\nAccuracy: %.2f\" % accuracy + \"%\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[0 0 0 0 1 1 1] [0 0 0 0 1 1 1]\n","\n","Accuracy: 100.00%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NZ6pVjkXvrw3"},"source":["import cv2\n","vidcap = cv2.VideoCapture('/content/drive/MyDrive/NewActivity/Lion/data/Lion2.mp4')\n","success,img = vidcap.read()\n","while success: \n","    X=[]\n","    success,img = vidcap.read()\n","    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","    img = cv2.resize(img,(128,128))\n","    des, hog_image = hog(img, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(4, 4), block_norm= 'L2',visualize=True)\n","    X.append(des)\n","    X = np.array(X)\n","    if(clfZZZZZZZZZ.predict(X)[0]==0):\n","        print(\"Angry\")\n","    else:\n","        print(\"Normal\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":885},"id":"8FgPgZkFoJVL","executionInfo":{"status":"error","timestamp":1628073569866,"user_tz":-330,"elapsed":16604,"user":{"displayName":"PRAJWAL RAJ B R","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuRCrK1ZO7-fWr_9umDkGnubnaSb19F5itGz5O=s64","userId":"02884760098419565384"}},"outputId":"cee8b5a2-005d-4d8e-88be-e0294792a2c5"},"source":["\n","import cv2\n","vidcap = cv2.VideoCapture('/content/drive/MyDrive/NewActivity/Lion/data/Lion2.mp4')\n","# vidcap = cv2.VideoCapture('/content/drive/MyDrive/NewActivity/Tiger/data/Tiger7.mp4')\n","success,img_o = vidcap.read()\n","img = cv2.cvtColor(img_o,cv2.COLOR_BGR2RGB)\n","while success:\n","  img = tf.keras.preprocessing.image.img_to_array(img)\n","  predicted = predict_class(cv2.resize(img, (224,224)))\n","\n","  if predicted == \"lion\":\n","    X=[]\n","    success,image = vidcap.read()\n","    imge = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n","    imge = cv2.resize(imge,(128,128))\n","    des, hog_image = hog(imge, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(4, 4), block_norm= 'L2',visualize=True)\n","    X.append(des)\n","    X = np.array(X)\n","    if(clfl.predict(X)[0]==0):\n","        print(predicted,\"- Angry\")\n","    else:\n","        print(predicted,\"- Normal\")\n","\n","  elif predicted == \"tiger\":\n","    X=[]\n","    success,image = vidcap.read()\n","    imge = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n","    imge = cv2.resize(imge,(128,128))\n","    des, hog_image = hog(imge, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(4, 4), block_norm= 'L2',visualize=True)\n","    X.append(des)\n","    X = np.array(X)\n","    if(clft.predict(X)[0]==0):\n","        print(predicted,\"- Angry\")\n","    else:\n","        print(predicted,\"- Normal\")\n","\n","  else:\n","    print(predicted)\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["lion - Normal\n","lion - Normal\n","lion - Normal\n","lion - Normal\n","lion - Normal\n","lion - Normal\n","lion - Normal\n","lion - Normal\n","lion - Normal\n","lion - Normal\n","lion - Normal\n","lion - Normal\n","lion - Normal\n","lion - Angry\n","lion - Normal\n","lion - Angry\n","lion - Angry\n","lion - Angry\n","lion - Angry\n","lion - Angry\n","lion - Angry\n","lion - Normal\n","lion - Normal\n","lion - Normal\n","lion - Normal\n","lion - Angry\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-b036a273f06b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"lion\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-62748f3584df>\u001b[0m in \u001b[0;36mpredict_class\u001b[0;34m(img_array)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimg_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimg_preprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_preprocessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1725\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"5Z3wXKJxpaLD","executionInfo":{"status":"ok","timestamp":1628058044285,"user_tz":-330,"elapsed":8,"user":{"displayName":"PRAJWAL RAJ B R","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuRCrK1ZO7-fWr_9umDkGnubnaSb19F5itGz5O=s64","userId":"02884760098419565384"}}},"source":[""],"execution_count":17,"outputs":[]}]}